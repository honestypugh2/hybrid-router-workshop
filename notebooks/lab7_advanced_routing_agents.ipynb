{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154b96aa",
   "metadata": {},
   "source": [
    "# Lab 7 (Advanced): Multi-Router Hybrid AI with Azure AI Foundry Agents\n",
    "\n",
    "**Purpose:** Build an advanced Streamlit interface demonstrating multiple routing strategies with Azure AI Foundry Agents for cloud processing.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This advanced lab demonstrates:\n",
    "- Multiple routing strategies (Rule-based, BERT, Phi SLM)\n",
    "- Azure AI Foundry Agents for sophisticated cloud processing\n",
    "- Side-by-side router comparison\n",
    "- Advanced telemetry and performance analysis\n",
    "- Production-ready hybrid architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e65ffae",
   "metadata": {},
   "source": [
    "## Step 7A.1: Import Dependencies and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e2e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory for module imports\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Base dependencies loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b110b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Azure AI Foundry Agents\n",
    "try:\n",
    "    from azure.ai.projects import AIProjectClient\n",
    "    from azure.ai.agents.models import CodeInterpreterTool\n",
    "    from azure.identity import DefaultAzureCredential\n",
    "    foundry_agents_available = True\n",
    "    print(\"‚úÖ Azure AI Foundry Agents SDK available\")\n",
    "except ImportError as e:\n",
    "    foundry_agents_available = False\n",
    "    print(f\"‚ö†Ô∏è Azure AI Foundry Agents not available: {e}\")\n",
    "\n",
    "# Import OpenAI clients\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "\n",
    "# Import local foundry manager\n",
    "from foundry_local import FoundryLocalManager\n",
    "\n",
    "# Import routing modules\n",
    "try:\n",
    "    from modules.router import analyze_query_characteristics, route_query\n",
    "    from modules.bert_router import BertQueryRouter, BertRouterConfig\n",
    "    from modules.phi_router import PhiQueryRouter, PhiRouterConfig\n",
    "    routing_modules_available = True\n",
    "    print(\"‚úÖ All routing modules imported\")\n",
    "except ImportError as e:\n",
    "    routing_modules_available = False\n",
    "    print(f\"‚ö†Ô∏è Some routing modules not available: {e}\")\n",
    "\n",
    "print(f\"Configuration status:\")\n",
    "print(f\"  - Foundry Agents: {foundry_agents_available}\")\n",
    "print(f\"  - Routing Modules: {routing_modules_available}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9182cc",
   "metadata": {},
   "source": [
    "## Step 7A.2: Initialize Local and Cloud Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006976c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize local foundry manager\n",
    "manager = FoundryLocalManager(alias_or_model_id=None, bootstrap=True)\n",
    "LOCAL_ENDPOINT = manager.service_uri\n",
    "LOCAL_MODEL_NAME = \"Phi-3.5-mini-instruct-generic-cpu\"  # Fixed model name\n",
    "\n",
    "print(f\"Local service: {LOCAL_ENDPOINT}\")\n",
    "print(f\"Local model: {LOCAL_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf94a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_advanced_clients():\n",
    "    \"\"\"Initialize all clients: local, Azure OpenAI, and Azure AI Foundry Agents.\"\"\"\n",
    "    clients = {\n",
    "        'local': None,\n",
    "        'azure_openai': None, \n",
    "        'azure_agent': None,\n",
    "        'status': {}\n",
    "    }\n",
    "    \n",
    "    # Local OpenAI client\n",
    "    try:\n",
    "        clients['local'] = OpenAI(\n",
    "            base_url=f\"{LOCAL_ENDPOINT}/v1\",\n",
    "            api_key=\"not-needed\"\n",
    "        )\n",
    "        clients['local_model'] = LOCAL_MODEL_NAME\n",
    "        clients['status']['local'] = '‚úÖ Ready'\n",
    "        print(f\"‚úÖ Local client: {LOCAL_MODEL_NAME}\")\n",
    "    except Exception as e:\n",
    "        clients['status']['local'] = f'‚ùå Failed: {e}'\n",
    "        print(f\"‚ùå Local client failed: {e}\")\n",
    "    \n",
    "    # Azure OpenAI client (fallback)\n",
    "    try:\n",
    "        clients['azure_openai'] = AzureOpenAI(\n",
    "            api_key=os.environ[\"AZURE_OPENAI_KEY\"],\n",
    "            api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "            azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "        )\n",
    "        clients['azure_model'] = os.environ[\"AZURE_DEPLOYMENT_NAME\"]\n",
    "        clients['status']['azure_openai'] = '‚úÖ Ready'\n",
    "        print(f\"‚úÖ Azure OpenAI: {clients['azure_model']}\")\n",
    "    except Exception as e:\n",
    "        clients['status']['azure_openai'] = f'‚ùå Failed: {e}'\n",
    "        print(f\"‚ùå Azure OpenAI failed: {e}\")\n",
    "    \n",
    "    # Azure AI Foundry Agent client\n",
    "    try:\n",
    "        if foundry_agents_available:\n",
    "            project_client = AIProjectClient(\n",
    "                endpoint=os.environ[\"AZURE_AI_FOUNDRY_ENDPOINT\"],\n",
    "                credential=DefaultAzureCredential()\n",
    "            )\n",
    "            clients['azure_agent'] = project_client\n",
    "            clients['status']['azure_agent'] = '‚úÖ Ready'\n",
    "            print(\"‚úÖ Azure AI Foundry Agent client ready\")\n",
    "        else:\n",
    "            clients['status']['azure_agent'] = '‚ö†Ô∏è SDK not available'\n",
    "    except Exception as e:\n",
    "        clients['status']['azure_agent'] = f'‚ùå Failed: {e}'\n",
    "        print(f\"‚ùå Azure AI Foundry Agent failed: {e}\")\n",
    "    \n",
    "    return clients\n",
    "\n",
    "# Initialize all clients\n",
    "clients = initialize_advanced_clients()\n",
    "print(f\"\\nüìä Client Status Summary:\")\n",
    "for name, status in clients['status'].items():\n",
    "    print(f\"  {name}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2e3f6",
   "metadata": {},
   "source": [
    "## Step 7A.3: Initialize Multiple Routers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bfce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import specialized routers from modules\n",
    "try:\n",
    "    from modules.bert_router import BertQueryRouter, BertRouterConfig\n",
    "    bert_available = True\n",
    "    print(\"‚úÖ BERT router module imported\")\n",
    "except ImportError as e:\n",
    "    bert_available = False\n",
    "    print(f\"‚ö†Ô∏è BERT router not available: {e}\")\n",
    "\n",
    "\n",
    "routers = {\n",
    "'rule_based': True,\n",
    "'bert': None,\n",
    "'phi': None,\n",
    "'status': {}\n",
    "}\n",
    "\n",
    "# Rule-based router (always available)\n",
    "routers['status']['rule_based'] = '‚úÖ Ready'\n",
    "print(\"‚úÖ Rule-based router ready\")\n",
    "\n",
    "bert_config = BertRouterConfig(\n",
    "            model_path=\"./mobilbert_query_router_trained\",\n",
    "            confidence_threshold=0.7\n",
    ")\n",
    "bert_router = BertQueryRouter(bert_config)\n",
    "bert_router._load_model()\n",
    "if bert_available:\n",
    "    routers['bert'] = bert_router\n",
    "    routers['status']['bert'] = '‚úÖ Ready'\n",
    "    print(\"‚úÖ BERT router loaded\")\n",
    "else:\n",
    "    routers['status']['bert'] = '‚ö†Ô∏è Model not found'\n",
    "    print(\"‚ö†Ô∏è BERT model not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_routers():\n",
    "    \"\"\"Initialize all available routing strategies.\"\"\"\n",
    "    routers = {\n",
    "        'rule_based': True,\n",
    "        'bert': None,\n",
    "        'phi': None,\n",
    "        'status': {}\n",
    "    }\n",
    "    \n",
    "    # Rule-based router (always available)\n",
    "    routers['status']['rule_based'] = '‚úÖ Ready'\n",
    "    print(\"‚úÖ Rule-based router ready\")\n",
    "    \n",
    "    # BERT router\n",
    "    # Import specialized routers from modules\n",
    "    try:\n",
    "        from modules.bert_router import BertQueryRouter, BertRouterConfig\n",
    "        bert_available = True\n",
    "        print(\"‚úÖ BERT router module imported\")\n",
    "    except ImportError as e:\n",
    "        bert_available = False\n",
    "        print(f\"‚ö†Ô∏è BERT router not available: {e}\")\n",
    "\n",
    "    try:\n",
    "        if routing_modules_available:\n",
    "            bert_config = BertRouterConfig()\n",
    "            bert_router = BertQueryRouter(bert_config)\n",
    "            bert_router._load_model()\n",
    "            if bert_available:\n",
    "                routers['bert'] = bert_router\n",
    "                routers['status']['bert'] = '‚úÖ Ready'\n",
    "                print(\"‚úÖ BERT router loaded\")\n",
    "            else:\n",
    "                routers['status']['bert'] = '‚ö†Ô∏è Model not found'\n",
    "                print(\"‚ö†Ô∏è BERT model not found\")\n",
    "        else:\n",
    "            routers['status']['bert'] = '‚ùå Module unavailable'\n",
    "    except Exception as e:\n",
    "        routers['status']['bert'] = f'‚ùå Failed: {str(e)[:50]}'\n",
    "        print(f\"‚ùå BERT router failed: {e}\")\n",
    "    \n",
    "    # Phi router\n",
    "    try:\n",
    "        if routing_modules_available:\n",
    "            phi_config = PhiRouterConfig(model_path=\"./phi_router_model\")\n",
    "            phi_router = PhiQueryRouter(phi_config)\n",
    "            if phi_router.load_model():\n",
    "                routers['phi'] = phi_router\n",
    "                routers['status']['phi'] = '‚úÖ Ready'\n",
    "                print(\"‚úÖ Phi router loaded\")\n",
    "            else:\n",
    "                routers['status']['phi'] = '‚ö†Ô∏è Model not found'\n",
    "                print(\"‚ö†Ô∏è Phi model not found\")\n",
    "        else:\n",
    "            routers['status']['phi'] = '‚ùå Module unavailable'\n",
    "    except Exception as e:\n",
    "        routers['status']['phi'] = f'‚ùå Failed: {str(e)[:50]}'\n",
    "        print(f\"‚ùå Phi router failed: {e}\")\n",
    "    \n",
    "    return routers\n",
    "\n",
    "# Initialize routers\n",
    "routers = initialize_routers()\n",
    "print(f\"\\nüìä Router Status Summary:\")\n",
    "for name, status in routers['status'].items():\n",
    "    print(f\"  {name}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9882380",
   "metadata": {},
   "source": [
    "## Step 7A.4: Create Advanced Routing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_with_strategy(query: str, strategy: str = 'rule_based') -> Tuple[str, str, float]:\n",
    "    \"\"\"Route query using specified strategy.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        if strategy == 'rule_based':\n",
    "            analysis = analyze_query_characteristics(query)\n",
    "            target, reason = route_query(query, analysis)\n",
    "            confidence = 0.85  # Default confidence\n",
    "            \n",
    "        elif strategy == 'bert' and routers['bert']:\n",
    "            result = routers['bert'].route_query(query)\n",
    "            target = result['prediction']\n",
    "            reason = f\"BERT: {result['reasoning']}\"\n",
    "            confidence = result['confidence']\n",
    "            \n",
    "        elif strategy == 'phi' and routers['phi']:\n",
    "            result = routers['phi'].route_query(query)\n",
    "            target = result['prediction']\n",
    "            reason = f\"Phi: {result['reasoning']}\"\n",
    "            confidence = result['confidence']\n",
    "            \n",
    "        else:\n",
    "            # Fallback to rule-based\n",
    "            analysis = analyze_query_characteristics(query)\n",
    "            target, reason = route_query(query, analysis)\n",
    "            confidence = 0.75\n",
    "            reason = f\"Fallback: {reason}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        target, reason, confidence = 'cloud', f'Error routing: {e}', 0.5\n",
    "    \n",
    "    routing_time = time.time() - start_time\n",
    "    return target, reason, confidence\n",
    "\n",
    "def generate_response_with_foundry(query: str, chat_history: List = None) -> Tuple[str, float]:\n",
    "    \"\"\"Generate response using Azure AI Foundry Agents.\"\"\"\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        if clients['azure_agent']:\n",
    "            # Create agent for complex processing\n",
    "            agent = clients['azure_agent'].agents.create_agent(\n",
    "                model=clients['azure_model'],\n",
    "                name=\"hybrid-assistant\",\n",
    "                instructions=\"You are a helpful AI assistant with access to advanced reasoning capabilities.\",\n",
    "                tools=[CodeInterpreterTool()]\n",
    "            )\n",
    "            \n",
    "            # Create thread and get response\n",
    "            thread = clients['azure_agent'].agents.threads.create()\n",
    "            \n",
    "            # Add message to thread\n",
    "            clients['azure_agent'].agents.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=query\n",
    "            )\n",
    "            \n",
    "            # Run agent\n",
    "            run = clients['azure_agent'].agents.runs.create_and_process(\n",
    "                thread_id=thread.id,\n",
    "                agent_id=agent.id\n",
    "            )\n",
    "            \n",
    "            # Wait for completion\n",
    "            while run.status in ['queued', 'in_progress']:\n",
    "                time.sleep(1)\n",
    "                run = clients['azure_agent'].agents.runs.get(thread.id, run.id)\n",
    "            \n",
    "            # Get messages\n",
    "            messages = clients['azure_agent'].agents.messages.list(thread.id)\n",
    "            response = messages.data[0].content[0].text.value\n",
    "            \n",
    "            # Cleanup\n",
    "            clients['azure_agent'].agents.delete_agent(agent.id)\n",
    "            clients['azure_agent'].agents.delete_thread(thread.id)\n",
    "            \n",
    "        else:\n",
    "            # Fallback to Azure OpenAI\n",
    "            messages = chat_history + [{\"role\": \"user\", \"content\": query}]\n",
    "            response_obj = clients['azure_openai'].chat.completions.create(\n",
    "                model=clients['azure_model'],\n",
    "                messages=messages,\n",
    "                max_tokens=400,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            response = response_obj.choices[0].message.content\n",
    "            \n",
    "    except Exception as e:\n",
    "        response = f\"Error generating response: {e}\"\n",
    "    \n",
    "    response_time = time.time() - start_time\n",
    "    return response, response_time\n",
    "\n",
    "def generate_multi_router_response(query: str, chat_history: List = None) -> Dict[str, Any]:\n",
    "    \"\"\"Generate response using multiple routing strategies for comparison.\"\"\"\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "    \n",
    "    results = {\n",
    "        'query': query,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'routing_results': {},\n",
    "        'final_response': None,\n",
    "        'response_time': 0,\n",
    "        'source': None\n",
    "    }\n",
    "    \n",
    "    # Test all available routers\n",
    "    strategies = ['rule_based', 'bert', 'phi']\n",
    "    for strategy in strategies:\n",
    "        target, reason, confidence = route_with_strategy(query, strategy)\n",
    "        results['routing_results'][strategy] = {\n",
    "            'target': target,\n",
    "            'reason': reason,\n",
    "            'confidence': confidence,\n",
    "            'available': routers['status'].get(strategy, '‚ùå').startswith('‚úÖ')\n",
    "        }\n",
    "    \n",
    "    # Use primary strategy (rule_based) for actual response\n",
    "    primary_target = results['routing_results']['rule_based']['target']\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        if primary_target == 'local' and clients['local']:\n",
    "            messages = chat_history + [{\"role\": \"user\", \"content\": query}]\n",
    "            response_obj = clients['local'].chat.completions.create(\n",
    "                model=clients['local_model'],\n",
    "                messages=messages,\n",
    "                max_tokens=200,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            results['final_response'] = response_obj.choices[0].message.content\n",
    "            results['source'] = 'Local'\n",
    "            \n",
    "        else:\n",
    "            # Use Azure AI Foundry Agents for cloud processing\n",
    "            response, _ = generate_response_with_foundry(query, chat_history)\n",
    "            results['final_response'] = response\n",
    "            results['source'] = 'Azure AI Foundry' if clients['azure_agent'] else 'Azure OpenAI'\n",
    "            \n",
    "    except Exception as e:\n",
    "        results['final_response'] = f\"Error: {e}\"\n",
    "        results['source'] = 'Error'\n",
    "    \n",
    "    results['response_time'] = time.time() - start_time\n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Advanced routing functions created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104c902",
   "metadata": {},
   "source": [
    "## Step 7A.5: Test Multi-Router System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the multi-router system\n",
    "test_queries = [\n",
    "    \"Hello!\",\n",
    "    \"What is 42 * 7?\",\n",
    "    \"Analyze the impact of hybrid AI architectures on enterprise productivity\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing Multi-Router System:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{i}. Query: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    result = generate_multi_router_response(query)\n",
    "    \n",
    "    # Show routing decisions\n",
    "    print(\"Router Decisions:\")\n",
    "    for strategy, data in result['routing_results'].items():\n",
    "        status = \"‚úÖ\" if data['available'] else \"‚ùå\"\n",
    "        print(f\"  {status} {strategy}: {data['target']} (conf: {data['confidence']:.2f})\")\n",
    "    \n",
    "    # Show response\n",
    "    print(f\"\\nüìù Response ({result['source']}):\") \n",
    "    response_preview = result['final_response'][:100] + \"...\" if len(result['final_response']) > 100 else result['final_response']\n",
    "    print(f\"   {response_preview}\")\n",
    "    print(f\"‚è±Ô∏è  Time: {result['response_time']:.3f}s\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Multi-router testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84900a7b",
   "metadata": {},
   "source": [
    "## Step 7A.6: Create Advanced Streamlit Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22390448",
   "metadata": {},
   "source": [
    "## üéâ Lab 7A Complete!\n",
    "\n",
    "### Advanced Features Implemented:\n",
    "- ‚úÖ **Multiple Routing Strategies**: Rule-based, BERT, and Phi SLM routers\n",
    "- ‚úÖ **Azure AI Foundry Agents**: Advanced cloud processing with agent capabilities\n",
    "- ‚úÖ **Router Comparison**: Side-by-side analysis of routing decisions\n",
    "- ‚úÖ **Advanced Telemetry**: Detailed performance metrics and visualization\n",
    "- ‚úÖ **Production Architecture**: Robust error handling and fallback mechanisms\n",
    "\n",
    "### Key Differentiators from Basic Lab 7:\n",
    "1. **Multi-Router Support**: Compare different routing algorithms in real-time\n",
    "2. **Azure AI Foundry**: Advanced agent-based processing for complex queries\n",
    "3. **Enhanced Analytics**: Routing distribution charts and performance tracking\n",
    "4. **Modular Design**: Easy to add new routing strategies\n",
    "5. **Professional UI**: Advanced Streamlit interface with detailed debugging\n",
    "\n",
    "### Demonstration Value:\n",
    "Perfect for showcasing the evolution of AI routing from simple rules to advanced ML-based decisions, while leveraging Azure's most sophisticated AI services for cloud processing.\n",
    "\n",
    "üöÄ **Run**: `streamlit run app_advanced.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
