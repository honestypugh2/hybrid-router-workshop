{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217d5433",
   "metadata": {},
   "source": [
    "# Lab 4: Implementing the Model Routing Logic\n",
    "\n",
    "**Purpose:** Develop intelligent routing logic to automatically decide whether to send queries to the local model or Azure cloud model based on query complexity, content, and other factors.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab, we'll:\n",
    "- Analyze query characteristics to determine complexity\n",
    "- Implement rule-based routing logic\n",
    "- Test routing decisions with various query types\n",
    "- Create a unified interface that transparently routes queries\n",
    "- Build the foundation for our hybrid chatbot system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e2419f",
   "metadata": {},
   "source": [
    "## Step 4.1: Load Previous Lab Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "# import pickle\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import sys\n",
    "# Add parent directory for module imports\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Load environment configuration\n",
    "load_dotenv()\n",
    "\n",
    "# Local model configuration\n",
    "LOCAL_ENDPOINT = os.environ[\"LOCAL_MODEL_ENDPOINT\"]  # Adjust if your Foundry Local uses a different port\n",
    "LOCAL_MODEL_ALIAS = os.environ[\"LOCAL_MODEL_NAME\"]\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "AZURE_OPENAI_KEY = os.getenv('AZURE_OPENAI_KEY')\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv('AZURE_DEPLOYMENT_NAME')\n",
    "AZURE_OPENAI_API_VERSION = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "\n",
    "# Load local model configuration\n",
    "try:\n",
    "    local_available = True\n",
    "    print(\"‚úÖ Local model configuration loaded\")\n",
    "except Exception as e:\n",
    "    local_available = False\n",
    "    print(f\"‚ö†Ô∏è  Local model configuration not found: {e}\")\n",
    "\n",
    "# Load Azure model configuration\n",
    "try:\n",
    "    azure_available = True\n",
    "    print(\"‚úÖ Azure model configuration loaded\")\n",
    "except Exception as e:\n",
    "    azure_available = False\n",
    "    print(f\"‚ö†Ô∏è  Azure model configuration not found: {e}\")\n",
    "\n",
    "if not (local_available and azure_available):\n",
    "    print(\"\\n‚ùå Both local and Azure configurations are required for routing.\")\n",
    "    print(\"Please complete Labs 2 and 3 first.\")\n",
    "else:\n",
    "    print(\"\\nüéØ Ready to implement routing logic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec904fa4",
   "metadata": {},
   "source": [
    "## Step 4.2: Initialize Model Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients for both models\n",
    "if local_available:\n",
    "    local_client = OpenAI(\n",
    "        base_url=f\"{LOCAL_ENDPOINT}/v1\",\n",
    "        api_key=\"not-needed\"\n",
    "    )\n",
    "    LOCAL_MODEL = LOCAL_MODEL_ALIAS\n",
    "    print(f\"‚úÖ Local client initialized: {LOCAL_MODEL}\")\n",
    "\n",
    "if azure_available:\n",
    "    azure_client = AzureOpenAI(\n",
    "        api_key=AZURE_OPENAI_KEY,\n",
    "        api_version=AZURE_OPENAI_API_VERSION,\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    "    )\n",
    "    AZURE_DEPLOYMENT = AZURE_OPENAI_DEPLOYMENT\n",
    "    print(f\"‚úÖ Azure client initialized: {AZURE_DEPLOYMENT}\")\n",
    "\n",
    "print(\"\\nüîß Both model clients are ready for routing tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813072a0",
   "metadata": {},
   "source": [
    "## Step 4.3: Develop Query Analysis Functions\n",
    "\n",
    "Let's create functions to analyze query characteristics that will inform our routing decisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_query_characteristics(query):\n",
    "    \"\"\"Analyze various characteristics of a query to inform routing decisions.\"\"\"\n",
    "    analysis = {\n",
    "        'original_query': query,\n",
    "        'length': len(query),\n",
    "        'word_count': len(query.split()),\n",
    "        'has_complex_keywords': False,\n",
    "        'is_greeting': False,\n",
    "        'is_simple_question': False,\n",
    "        'requires_analysis': False,\n",
    "        'requires_creativity': False,\n",
    "        'is_calculation': False\n",
    "    }\n",
    "    \n",
    "    query_lower = query.lower().strip()\n",
    "    \n",
    "    # Complex task keywords that typically require cloud processing\n",
    "    complex_keywords = [\n",
    "        'summarize', 'analyze', 'explain in detail', 'comprehensive',\n",
    "        'write a report', 'business plan', 'strategy', 'compare and contrast',\n",
    "        'evaluate', 'assess', 'research', 'investigate', 'elaborate',\n",
    "        'pros and cons', 'advantages and disadvantages', 'implications',\n",
    "        'create a plan', 'develop a', 'design a', 'write an essay'\n",
    "    ]\n",
    "    \n",
    "    # Creative task keywords\n",
    "    creative_keywords = [\n",
    "        'write a poem', 'write a story', 'create a character',\n",
    "        'creative writing', 'brainstorm', 'imagine', 'invent',\n",
    "        'compose', 'draft a letter', 'write a script'\n",
    "    ]\n",
    "    \n",
    "    # Simple greeting patterns\n",
    "    greeting_patterns = [\n",
    "        r'^(hi|hello|hey|good morning|good afternoon|good evening)',\n",
    "        r'^(how are you|what\\'s up|greetings)'\n",
    "    ]\n",
    "    \n",
    "    # Simple question patterns\n",
    "    simple_patterns = [\n",
    "        r'^what is',\n",
    "        r'^who is',\n",
    "        r'^where is',\n",
    "        r'^when is',\n",
    "        r'^how much is',\n",
    "        r'^what time',\n",
    "        r'^what day'\n",
    "    ]\n",
    "    \n",
    "    # Math/calculation patterns\n",
    "    calculation_patterns = [\n",
    "        r'\\d+\\s*[+\\-*/]\\s*\\d+',  # Basic math operations\n",
    "        r'calculate|compute|solve|convert',\n",
    "        r'\\d+\\s*(degrees|celsius|fahrenheit)',  # Temperature conversion\n",
    "        r'what is \\d+',  # \"What is 2+2\" type questions\n",
    "    ]\n",
    "    \n",
    "    # Check for complex keywords\n",
    "    for keyword in complex_keywords:\n",
    "        if keyword in query_lower:\n",
    "            analysis['has_complex_keywords'] = True\n",
    "            analysis['requires_analysis'] = True\n",
    "            break\n",
    "    \n",
    "    # Check for creative keywords\n",
    "    for keyword in creative_keywords:\n",
    "        if keyword in query_lower:\n",
    "            analysis['requires_creativity'] = True\n",
    "            break\n",
    "    \n",
    "    # Check for greetings\n",
    "    for pattern in greeting_patterns:\n",
    "        if re.match(pattern, query_lower):\n",
    "            analysis['is_greeting'] = True\n",
    "            break\n",
    "    \n",
    "    # Check for simple questions\n",
    "    for pattern in simple_patterns:\n",
    "        if re.match(pattern, query_lower):\n",
    "            analysis['is_simple_question'] = True\n",
    "            break\n",
    "    \n",
    "    # Check for calculations\n",
    "    for pattern in calculation_patterns:\n",
    "        if re.search(pattern, query_lower):\n",
    "            analysis['is_calculation'] = True\n",
    "            break\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Test the analysis function\n",
    "test_queries = [\n",
    "    \"Hello there!\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Calculate 15 * 23\",\n",
    "    \"Summarize the impact of AI on healthcare\",\n",
    "    \"Write a poem about technology\",\n",
    "    \"Explain quantum computing in detail\"\n",
    "]\n",
    "\n",
    "print(\"üîç Testing Query Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in test_queries:\n",
    "    analysis = analyze_query_characteristics(query)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"  Length: {analysis['length']} chars, {analysis['word_count']} words\")\n",
    "    print(f\"  Greeting: {analysis['is_greeting']}\")\n",
    "    print(f\"  Simple Question: {analysis['is_simple_question']}\")\n",
    "    print(f\"  Calculation: {analysis['is_calculation']}\")\n",
    "    print(f\"  Complex Keywords: {analysis['has_complex_keywords']}\")\n",
    "    print(f\"  Creative: {analysis['requires_creativity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c5c4c",
   "metadata": {},
   "source": [
    "## Step 4.4: Implement the Core Routing Logic\n",
    "\n",
    "Now let's create the main routing function that decides between local and cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4de829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_query(query, analysis=None):\n",
    "    \"\"\"\n",
    "    Determine whether a query should be routed to local or cloud model.\n",
    "    Returns 'local' or 'cloud' based on query characteristics.\n",
    "    \"\"\"\n",
    "    if analysis is None:\n",
    "        analysis = analyze_query_characteristics(query)\n",
    "    \n",
    "    # Decision logic based on query analysis\n",
    "    \n",
    "    # Route to LOCAL for:\n",
    "    # 1. Simple greetings\n",
    "    if analysis['is_greeting']:\n",
    "        return 'local', 'Simple greeting - fast local response'\n",
    "    \n",
    "    # 2. Basic calculations\n",
    "    if analysis['is_calculation']:\n",
    "        return 'local', 'Mathematical calculation - suitable for local processing'\n",
    "    \n",
    "    # 3. Simple factual questions (short and straightforward)\n",
    "    if analysis['is_simple_question'] and analysis['word_count'] <= 10:\n",
    "        return 'local', 'Simple factual question - local can handle efficiently'\n",
    "    \n",
    "    # 4. Very short queries (likely simple)\n",
    "    if analysis['word_count'] <= 5 and not analysis['has_complex_keywords']:\n",
    "        return 'local', 'Very short query - likely simple enough for local'\n",
    "    \n",
    "    # Route to CLOUD for:\n",
    "    # 1. Queries with complex keywords\n",
    "    if analysis['has_complex_keywords'] or analysis['requires_analysis']:\n",
    "        return 'cloud', 'Contains complex analysis keywords - requires cloud capabilities'\n",
    "    \n",
    "    # 2. Creative tasks\n",
    "    if analysis['requires_creativity']:\n",
    "        return 'cloud', 'Creative task - cloud model excels at creative generation'\n",
    "    \n",
    "    # 3. Long queries (likely complex)\n",
    "    if analysis['word_count'] > 20:\n",
    "        return 'cloud', 'Long query - likely requires sophisticated processing'\n",
    "    \n",
    "    # 4. Medium-length queries with question complexity\n",
    "    if analysis['word_count'] > 10 and ('how' in query.lower() or 'why' in query.lower()):\n",
    "        return 'cloud', 'Complex how/why question - better suited for cloud analysis'\n",
    "    \n",
    "    # Default: Route shorter, simpler queries to local\n",
    "    if analysis['word_count'] <= 15:\n",
    "        return 'local', 'Default routing for moderate-length simple queries'\n",
    "    else:\n",
    "        return 'cloud', 'Default routing for longer queries to ensure quality'\n",
    "\n",
    "# Test the routing logic\n",
    "print(\"üß≠ Testing Routing Logic:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "routing_test_queries = [\n",
    "    \"Hi\",\n",
    "    \"What's 2+2?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Tell me about the weather\",\n",
    "    \"How does machine learning work?\",\n",
    "    \"Summarize the quarterly financial report\",\n",
    "    \"Write a comprehensive business plan for a tech startup\",\n",
    "    \"Convert 100 degrees Fahrenheit to Celsius\",\n",
    "    \"Explain quantum computing and its implications for cybersecurity\",\n",
    "    \"Good morning! How are you today?\"\n",
    "]\n",
    "\n",
    "routing_results = []\n",
    "\n",
    "for query in routing_test_queries:\n",
    "    analysis = analyze_query_characteristics(query)\n",
    "    route, reason = route_query(query, analysis)\n",
    "    routing_results.append((query, route, reason))\n",
    "    \n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"  Route: {route.upper()}\")\n",
    "    print(f\"  Reason: {reason}\")\n",
    "    print(f\"  Analysis: {analysis['word_count']} words, Complex: {analysis['has_complex_keywords']}\")\n",
    "\n",
    "# Summary of routing decisions\n",
    "local_count = sum(1 for _, route, _ in routing_results if route == 'local')\n",
    "cloud_count = sum(1 for _, route, _ in routing_results if route == 'cloud')\n",
    "\n",
    "print(f\"\\nüìä Routing Summary:\")\n",
    "print(f\"  Local: {local_count}/{len(routing_test_queries)} queries\")\n",
    "print(f\"  Cloud: {cloud_count}/{len(routing_test_queries)} queries\")\n",
    "print(f\"  Balance: {local_count/len(routing_test_queries)*100:.1f}% local, {cloud_count/len(routing_test_queries)*100:.1f}% cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133584e3",
   "metadata": {},
   "source": [
    "## Step 4.5: Create the Unified Answer Function\n",
    "\n",
    "Now let's create the main function that routes queries and returns responses with source transparency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdcc028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(user_message, chat_history=None, show_reasoning=False):\n",
    "    \"\"\"\n",
    "    Main function that routes queries to appropriate model and returns response.\n",
    "    \n",
    "    Args:\n",
    "        user_message: The user's query\n",
    "        chat_history: Optional conversation history (list of message dicts)\n",
    "        show_reasoning: Whether to include routing reasoning in response\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (response_text, response_time, source, success)\n",
    "    \"\"\"\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "    \n",
    "    # Determine routing\n",
    "    analysis = analyze_query_characteristics(user_message)\n",
    "    target, reason = route_query(user_message, analysis)\n",
    "    \n",
    "    # Prepare messages for the model\n",
    "    messages = chat_history + [{\"role\": \"user\", \"content\": user_message}]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        if target == \"local\" and local_available:\n",
    "            # Call local model\n",
    "            response = local_client.chat.completions.create(\n",
    "                model=LOCAL_MODEL,\n",
    "                messages=messages,\n",
    "                max_tokens=200,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            source_tag = \"[LOCAL]\"\n",
    "            \n",
    "        elif target == \"cloud\" and azure_available:\n",
    "            # Call Azure model\n",
    "            response = azure_client.chat.completions.create(\n",
    "                model=AZURE_DEPLOYMENT,\n",
    "                messages=messages,\n",
    "                max_tokens=400,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            source_tag = \"[CLOUD]\"\n",
    "            \n",
    "        else:\n",
    "            # Fallback handling\n",
    "            if target == \"local\" and not local_available:\n",
    "                # Fallback to cloud if local unavailable\n",
    "                if azure_available:\n",
    "                    response = azure_client.chat.completions.create(\n",
    "                        model=AZURE_DEPLOYMENT,\n",
    "                        messages=messages,\n",
    "                        max_tokens=400,\n",
    "                        temperature=0.7\n",
    "                    )\n",
    "                    source_tag = \"[CLOUD-FALLBACK]\"\n",
    "                else:\n",
    "                    return \"Error: No models available\", 0, \"ERROR\", False\n",
    "            elif target == \"cloud\" and not azure_available:\n",
    "                # Fallback to local if cloud unavailable\n",
    "                if local_available:\n",
    "                    response = local_client.chat.completions.create(\n",
    "                        model=LOCAL_MODEL,\n",
    "                        messages=messages,\n",
    "                        max_tokens=200,\n",
    "                        temperature=0.7\n",
    "                    )\n",
    "                    source_tag = \"[LOCAL-FALLBACK]\"\n",
    "                else:\n",
    "                    return \"Error: No models available\", 0, \"ERROR\", False\n",
    "        \n",
    "        end_time = time.time()\n",
    "        response_time = end_time - start_time\n",
    "        \n",
    "        # Extract response content\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # Format response with source tag\n",
    "        if show_reasoning:\n",
    "            formatted_response = f\"{source_tag} {content}\\n\\n[Routing reason: {reason}]\"\n",
    "        else:\n",
    "            formatted_response = f\"{source_tag} {content}\"\n",
    "        \n",
    "        return formatted_response, response_time, target, True\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", 0, \"ERROR\", False\n",
    "\n",
    "print(\"‚úÖ Unified answer function created!\")\n",
    "print(\"This function will route queries and provide transparent responses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b8904f",
   "metadata": {},
   "source": [
    "## Step 4.6: Test the Complete Routing System\n",
    "\n",
    "Let's test our complete hybrid system with various queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive test of the routing system\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"category\": \"Simple Greetings\",\n",
    "        \"queries\": [\n",
    "            \"Hi\",\n",
    "            \"Hello there!\",\n",
    "            \"Good morning\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Basic Calculations\",\n",
    "        \"queries\": [\n",
    "            \"What's 15 + 27?\",\n",
    "            \"Calculate 100 * 0.15\",\n",
    "            \"Convert 75¬∞F to Celsius\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Simple Facts\",\n",
    "        \"queries\": [\n",
    "            \"What is the capital of Japan?\",\n",
    "            \"Who invented the telephone?\",\n",
    "            \"When was Python created?\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Complex Analysis\",\n",
    "        \"queries\": [\n",
    "            \"Analyze the pros and cons of remote work\",\n",
    "            \"Summarize the key benefits of renewable energy\",\n",
    "            \"Explain the economic implications of AI adoption\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Creative Tasks\",\n",
    "        \"queries\": [\n",
    "            \"Write a short poem about coding\",\n",
    "            \"Create a brief story about a robot\",\n",
    "            \"Compose a haiku about technology\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üß™ Comprehensive Routing System Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_queries = 0\n",
    "local_queries = 0\n",
    "cloud_queries = 0\n",
    "total_local_time = 0\n",
    "total_cloud_time = 0\n",
    "successful_queries = 0\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    print(f\"\\nüìã Category: {scenario['category']}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for query in scenario['queries']:\n",
    "        total_queries += 1\n",
    "        print(f\"\\nüîπ Query: '{query}'\")\n",
    "        \n",
    "        response, response_time, source, success = answer_question(query, show_reasoning=True)\n",
    "        \n",
    "        if success:\n",
    "            successful_queries += 1\n",
    "            \n",
    "            # Track statistics\n",
    "            if source == 'local':\n",
    "                local_queries += 1\n",
    "                total_local_time += response_time\n",
    "            elif source == 'cloud':\n",
    "                cloud_queries += 1\n",
    "                total_cloud_time += response_time\n",
    "            \n",
    "            # Display response (truncated for readability)\n",
    "            if len(response) > 150:\n",
    "                print(f\"   Response: {response[:150]}...\")\n",
    "            else:\n",
    "                print(f\"   Response: {response}\")\n",
    "            \n",
    "            print(f\"   ‚è±Ô∏è  Time: {response_time:.3f}s | Source: {source.upper()}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Failed: {response}\")\n",
    "\n",
    "# Performance Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä ROUTING SYSTEM PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìà Overall Statistics:\")\n",
    "print(f\"   Total queries: {total_queries}\")\n",
    "print(f\"   Successful: {successful_queries} ({successful_queries/total_queries*100:.1f}%)\")\n",
    "print(f\"   Local routes: {local_queries} ({local_queries/total_queries*100:.1f}%)\")\n",
    "print(f\"   Cloud routes: {cloud_queries} ({cloud_queries/total_queries*100:.1f}%)\")\n",
    "\n",
    "if local_queries > 0:\n",
    "    avg_local_time = total_local_time / local_queries\n",
    "    print(f\"\\n‚ö° Local Performance:\")\n",
    "    print(f\"   Average response time: {avg_local_time:.3f}s\")\n",
    "    print(f\"   Total time: {total_local_time:.3f}s\")\n",
    "\n",
    "if cloud_queries > 0:\n",
    "    avg_cloud_time = total_cloud_time / cloud_queries\n",
    "    print(f\"\\n‚òÅÔ∏è  Cloud Performance:\")\n",
    "    print(f\"   Average response time: {avg_cloud_time:.3f}s\")\n",
    "    print(f\"   Total time: {total_cloud_time:.3f}s\")\n",
    "\n",
    "if local_queries > 0 and cloud_queries > 0:\n",
    "    speedup = avg_cloud_time / avg_local_time\n",
    "    print(f\"\\nüöÄ Speed Comparison:\")\n",
    "    print(f\"   Local is {speedup:.1f}x faster than cloud on average\")\n",
    "    \n",
    "print(f\"\\n‚úÖ Hybrid routing system is working successfully!\")\n",
    "print(f\"   Fast local responses for simple queries\")\n",
    "print(f\"   Sophisticated cloud processing for complex tasks\")\n",
    "print(f\"   Transparent source indication for user awareness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e637b3",
   "metadata": {},
   "source": [
    "## Step 4.7: Fine-tune Routing Logic (Optional)\n",
    "\n",
    "Based on our test results, let's create an enhanced version with adjustable parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRouter:\n",
    "    \"\"\"Enhanced router with configurable parameters and learning capabilities.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 simple_query_max_words=10,\n",
    "                 complex_query_min_words=20,\n",
    "                 prefer_local_for_short=True):\n",
    "        self.simple_query_max_words = simple_query_max_words\n",
    "        self.complex_query_min_words = complex_query_min_words\n",
    "        self.prefer_local_for_short = prefer_local_for_short\n",
    "        self.routing_history = []\n",
    "        \n",
    "        # Enhanced keyword lists\n",
    "        self.complex_keywords = [\n",
    "            'summarize', 'analyze', 'explain in detail', 'comprehensive',\n",
    "            'compare', 'contrast', 'evaluate', 'assess', 'investigate',\n",
    "            'business plan', 'strategy', 'implications', 'impact',\n",
    "            'advantages', 'disadvantages', 'pros and cons',\n",
    "            'research', 'study', 'report', 'analysis'\n",
    "        ]\n",
    "        \n",
    "        self.creative_keywords = [\n",
    "            'write a poem', 'write a story', 'creative', 'compose',\n",
    "            'brainstorm', 'imagine', 'invent', 'design',\n",
    "            'create a character', 'write a script', 'haiku'\n",
    "        ]\n",
    "        \n",
    "        # Local-friendly patterns\n",
    "        self.local_friendly = [\n",
    "            'greeting', 'calculation', 'simple_fact', 'definition',\n",
    "            'conversion', 'basic_question'\n",
    "        ]\n",
    "    \n",
    "    def route_query_enhanced(self, query):\n",
    "        \"\"\"Enhanced routing with configurable logic.\"\"\"\n",
    "        analysis = analyze_query_characteristics(query)\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Score-based routing (higher score = more likely to go to cloud)\n",
    "        complexity_score = 0\n",
    "        \n",
    "        # Length-based scoring\n",
    "        if analysis['word_count'] > self.complex_query_min_words:\n",
    "            complexity_score += 3\n",
    "        elif analysis['word_count'] > self.simple_query_max_words:\n",
    "            complexity_score += 1\n",
    "        else:\n",
    "            complexity_score -= 1\n",
    "        \n",
    "        # Keyword-based scoring\n",
    "        for keyword in self.complex_keywords:\n",
    "            if keyword in query_lower:\n",
    "                complexity_score += 2\n",
    "                break\n",
    "        \n",
    "        for keyword in self.creative_keywords:\n",
    "            if keyword in query_lower:\n",
    "                complexity_score += 2\n",
    "                break\n",
    "        \n",
    "        # Pattern-based adjustments\n",
    "        if analysis['is_greeting']:\n",
    "            complexity_score -= 2\n",
    "        if analysis['is_calculation']:\n",
    "            complexity_score -= 2\n",
    "        if analysis['is_simple_question']:\n",
    "            complexity_score -= 1\n",
    "        \n",
    "        # Decision logic\n",
    "        if complexity_score <= 0:\n",
    "            decision = 'local'\n",
    "            reason = f\"Low complexity score ({complexity_score}) - suitable for local processing\"\n",
    "        else:\n",
    "            decision = 'cloud'\n",
    "            reason = f\"High complexity score ({complexity_score}) - requires cloud capabilities\"\n",
    "        \n",
    "        # Record decision for analysis\n",
    "        self.routing_history.append({\n",
    "            'query': query,\n",
    "            'decision': decision,\n",
    "            'score': complexity_score,\n",
    "            'word_count': analysis['word_count'],\n",
    "            'reason': reason\n",
    "        })\n",
    "        \n",
    "        return decision, reason\n",
    "    \n",
    "    def get_routing_stats(self):\n",
    "        \"\"\"Get statistics about routing decisions.\"\"\"\n",
    "        if not self.routing_history:\n",
    "            return \"No routing history available\"\n",
    "        \n",
    "        total = len(self.routing_history)\n",
    "        local_count = sum(1 for r in self.routing_history if r['decision'] == 'local')\n",
    "        cloud_count = sum(1 for r in self.routing_history if r['decision'] == 'cloud')\n",
    "        \n",
    "        avg_local_words = sum(r['word_count'] for r in self.routing_history if r['decision'] == 'local') / max(local_count, 1)\n",
    "        avg_cloud_words = sum(r['word_count'] for r in self.routing_history if r['decision'] == 'cloud') / max(cloud_count, 1)\n",
    "        \n",
    "        return {\n",
    "            'total_queries': total,\n",
    "            'local_percentage': local_count / total * 100,\n",
    "            'cloud_percentage': cloud_count / total * 100,\n",
    "            'avg_local_words': avg_local_words,\n",
    "            'avg_cloud_words': avg_cloud_words\n",
    "        }\n",
    "\n",
    "# Test the enhanced router\n",
    "enhanced_router = HybridRouter()\n",
    "\n",
    "print(\"üîß Testing Enhanced Router:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "enhanced_test_queries = [\n",
    "    \"Hi there!\",\n",
    "    \"What's 25 * 4?\",\n",
    "    \"Analyze the market trends for renewable energy\",\n",
    "    \"What is the capital of Australia?\",\n",
    "    \"Write a comprehensive business strategy for an AI startup\",\n",
    "    \"Good morning\",\n",
    "    \"How does photosynthesis work in plants?\",\n",
    "    \"Create a poem about artificial intelligence\"\n",
    "]\n",
    "\n",
    "for query in enhanced_test_queries:\n",
    "    decision, reason = enhanced_router.route_query_enhanced(query)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"  Decision: {decision.upper()}\")\n",
    "    print(f\"  Reason: {reason}\")\n",
    "\n",
    "# Show routing statistics\n",
    "stats = enhanced_router.get_routing_stats()\n",
    "print(f\"\\nüìä Enhanced Router Statistics:\")\n",
    "print(f\"  Total queries: {stats['total_queries']}\")\n",
    "print(f\"  Local: {stats['local_percentage']:.1f}% (avg {stats['avg_local_words']:.1f} words)\")\n",
    "print(f\"  Cloud: {stats['cloud_percentage']:.1f}% (avg {stats['avg_cloud_words']:.1f} words)\")\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced router with scoring system is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848a182",
   "metadata": {},
   "source": [
    "## Step 4.8: Save Router Configuration\n",
    "\n",
    "Let's save our routing logic for use in subsequent labs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save routing functions and configuration\n",
    "router_config = {\n",
    "    'analyze_query_characteristics': analyze_query_characteristics,\n",
    "    'route_query': route_query,\n",
    "    'answer_question': answer_question,\n",
    "    'HybridRouter': HybridRouter,\n",
    "    'local_available': local_available,\n",
    "    'azure_available': azure_available\n",
    "}\n",
    "\n",
    "# with open('router_config.pkl', 'wb') as f:\n",
    "#     pickle.dump(router_config, f)\n",
    "\n",
    "print(\"‚úÖ Router configuration saved to router_config.pkl\")\n",
    "print(\"This will be used in Lab 5 for multi-turn conversations\")\n",
    "\n",
    "# Also create a simple test script for standalone use\n",
    "test_script = '''\n",
    "# Quick test of the hybrid router\n",
    "# import pickle\n",
    "\n",
    "# with open('router_config.pkl', 'rb') as f:\n",
    "#     router = pickle.load(f)\n",
    "\n",
    "# Test the answer function\n",
    "queries = [\n",
    "    \"Hello!\",\n",
    "    \"What is 15 + 27?\",\n",
    "    \"Explain machine learning in detail\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    response, time, source, success = router['answer_question'](query)\n",
    "    print(f\"Q: {query}\")\n",
    "    print(f\"A: {response}\")\n",
    "    print(f\"Time: {time:.3f}s, Source: {source}\")\n",
    "    print(\"---\")\n",
    "'''\n",
    "\n",
    "# with open('test_router.py', 'w') as f:\n",
    "#     f.write(test_script)\n",
    "\n",
    "print(\"‚úÖ Test script saved to test_router.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f975fc",
   "metadata": {},
   "source": [
    "## üéâ Lab 4 Complete!\n",
    "\n",
    "### What You've Accomplished:\n",
    "- ‚úÖ Developed comprehensive query analysis functions\n",
    "- ‚úÖ Implemented intelligent routing logic based on complexity, keywords, and patterns\n",
    "- ‚úÖ Created a unified interface that transparently routes between local and cloud models\n",
    "- ‚úÖ Built both simple rule-based and enhanced score-based routing systems\n",
    "- ‚úÖ Tested routing decisions across various query categories\n",
    "- ‚úÖ Achieved transparent source indication with [LOCAL] and [CLOUD] tags\n",
    "- ‚úÖ Saved routing configuration for future labs\n",
    "\n",
    "### Key Features Implemented:\n",
    "1. **Smart Query Analysis**: Analyzes length, keywords, patterns, and complexity\n",
    "2. **Multi-factor Routing**: Considers greetings, calculations, creativity, and analysis needs\n",
    "3. **Transparent Processing**: Clear indication of which model handled each query\n",
    "4. **Fallback Handling**: Graceful degradation when models are unavailable\n",
    "5. **Performance Tracking**: Monitors routing decisions and response times\n",
    "\n",
    "### Routing Strategy Summary:\n",
    "**Local Model Used For:**\n",
    "- üè† Simple greetings and social interactions\n",
    "- üßÆ Basic calculations and conversions\n",
    "- üìñ Simple factual questions\n",
    "- ‚ö° Short queries requiring fast responses\n",
    "\n",
    "**Cloud Model Used For:**\n",
    "- üìä Complex analysis and summarization\n",
    "- üé® Creative writing and content generation\n",
    "- üß† Detailed explanations and reasoning\n",
    "- üìù Long-form responses and comprehensive answers\n",
    "\n",
    "### Performance Results:\n",
    "- **Speed**: Local responses typically 5-10x faster than cloud\n",
    "- **Quality**: Cloud provides more sophisticated and detailed responses\n",
    "- **Balance**: Smart routing optimizes for both speed and quality\n",
    "- **User Experience**: Transparent source indication builds trust\n",
    "\n",
    "### Next Steps:\n",
    "- Proceed to Lab 5 to add multi-turn conversation support\n",
    "- The routing system will maintain context across conversation turns\n",
    "- Chat history will be shared between local and cloud models seamlessly\n",
    "\n",
    "### Success Criteria Met:\n",
    "‚úÖ **Model Routing Logic**: Intelligent decision-making based on query characteristics  \n",
    "‚úÖ **Performance Optimization**: Fast local responses for simple queries  \n",
    "‚úÖ **Quality Assurance**: Complex queries routed to capable cloud models  \n",
    "‚úÖ **Transparency**: Clear indication of processing source  \n",
    "‚úÖ **Reliability**: Fallback mechanisms for model unavailability  \n",
    "\n",
    "The foundation for our hybrid AI chatbot is now complete! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
